<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio2Face-3D Browser SDK Demo</title>
    <style>
        * { box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background: #1a1a2e;
            color: #eee;
            line-height: 1.6;
        }
        h1 { color: #00d4ff; margin-bottom: 10px; }
        .subtitle { color: #888; margin-bottom: 30px; }
        .controls {
            background: #16213e;
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 20px;
            border: 1px solid #0f3460;
        }
        h3 { margin-top: 0; color: #00d4ff; }
        button {
            background: #00d4ff;
            color: #1a1a2e;
            border: none;
            padding: 12px 24px;
            border-radius: 4px;
            cursor: pointer;
            font-size: 16px;
            margin: 5px;
            font-weight: 600;
            transition: all 0.2s;
        }
        button:hover:not(:disabled) { background: #00a8cc; transform: translateY(-1px); }
        button:disabled { background: #444; cursor: not-allowed; opacity: 0.6; }
        input[type="file"] { margin: 10px 0; color: #eee; }
        label { display: flex; align-items: center; gap: 8px; margin: 10px 0; cursor: pointer; }
        .status {
            padding: 12px;
            margin: 15px 0;
            border-radius: 4px;
            background: #0f3460;
            font-family: monospace;
            font-size: 14px;
        }
        .status.error { background: #5c1a1a; color: #ff6b6b; }
        .status.success { background: #1a5c1a; color: #6bff6b; }
        .status.loading { background: #5c4a1a; color: #ffd36b; }
        .blendshapes {
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(280px, 1fr));
            gap: 12px;
            margin-top: 20px;
            max-height: 600px;
            overflow-y: auto;
        }
        .blendshape {
            background: #0f3460;
            padding: 12px;
            border-radius: 6px;
            display: flex;
            flex-direction: column;
            gap: 6px;
        }
        .blendshape-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
        }
        .blendshape-name {
            font-size: 13px;
            color: #aaa;
            font-weight: 500;
        }
        .blendshape-value {
            font-family: monospace;
            font-size: 14px;
            color: #00d4ff;
            font-weight: 600;
        }
        .bar {
            width: 100%;
            height: 6px;
            background: #1a1a2e;
            border-radius: 3px;
            overflow: hidden;
        }
        .bar-fill {
            height: 100%;
            background: linear-gradient(90deg, #00d4ff, #00a8cc);
            border-radius: 3px;
            transition: width 0.1s ease-out;
        }
        #visualizer {
            width: 100%;
            height: 120px;
            background: #0f3460;
            border-radius: 4px;
            margin: 15px 0;
        }
        .stats {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 15px;
            margin: 15px 0;
        }
        .stat {
            background: #0f3460;
            padding: 15px;
            border-radius: 6px;
            text-align: center;
        }
        .stat-value {
            font-size: 24px;
            font-weight: bold;
            color: #00d4ff;
        }
        .stat-label {
            font-size: 12px;
            color: #888;
            margin-top: 5px;
        }
        .info-box {
            background: #1a3a5c;
            border-left: 4px solid #00d4ff;
            padding: 15px;
            margin: 15px 0;
            border-radius: 0 4px 4px 0;
        }
        .info-box h4 { margin: 0 0 10px 0; color: #00d4ff; }
        .info-box p { margin: 0; font-size: 14px; color: #ccc; }
        .progress-bar {
            width: 100%;
            height: 8px;
            background: #0f3460;
            border-radius: 4px;
            overflow: hidden;
            margin: 10px 0;
        }
        .progress-fill {
            height: 100%;
            background: linear-gradient(90deg, #00d4ff, #00a8cc);
            border-radius: 4px;
            transition: width 0.3s ease;
            width: 0%;
        }
    </style>
</head>
<body>
    <h1>Audio2Face-3D Browser SDK</h1>
    <p class="subtitle">Real-time audio-driven facial animation in the browser</p>
    
    <div class="info-box">
        <h4>Quick Start</h4>
        <p>The model loads automatically on page load. Once ready, use your microphone for real-time processing or upload an audio file.</p>
    </div>

    <div class="controls">
        <h3>Model Status</h3>
        <div id="modelStatus" class="status loading">Initializing...</div>
        <div class="progress-bar">
            <div id="progressFill" class="progress-fill"></div>
        </div>
        
        <div class="stats" id="modelStats" style="display: none;">
            <div class="stat">
                <div class="stat-value" id="backend">-</div>
                <div class="stat-label">Backend</div>
            </div>
            <div class="stat">
                <div class="stat-value" id="inputs">-</div>
                <div class="stat-label">Inputs</div>
            </div>
            <div class="stat">
                <div class="stat-value" id="outputs">-</div>
                <div class="stat-label">Outputs</div>
            </div>
            <div class="stat">
                <div class="stat-value" id="loadTime">-</div>
                <div class="stat-label">Load Time</div>
            </div>
        </div>
    </div>

    <div class="controls">
        <h3>Audio Input</h3>
        <button id="startMic" disabled>Start Microphone (Realtime)</button>
        <button id="stopMic" disabled>Stop Microphone</button>
        <br><br>
        <input type="file" id="audioFile" accept="audio/*" disabled />
        <button id="processFile" disabled>Process Audio File</button>
        <canvas id="visualizer"></canvas>
        
        <div class="stats" id="audioStats" style="display: none;">
            <div class="stat">
                <div class="stat-value" id="fps">0</div>
                <div class="stat-label">FPS</div>
            </div>
            <div class="stat">
                <div class="stat-value" id="latency">0</div>
                <div class="stat-label">Latency (ms)</div>
            </div>
            <div class="stat">
                <div class="stat-value" id="chunks">0</div>
                <div class="stat-label">Chunks Processed</div>
            </div>
        </div>
    </div>

    <div class="controls">
        <h3>Blendshape Output</h3>
        <div id="outputStatus" class="status">Waiting for model to load...</div>
        <div id="blendshapes" class="blendshapes"></div>
    </div>

    <script src="onnxruntime-web.min.js"></script>
    <script type="module">
        import { Audio2FaceSDK } from './audio2face-sdk-browser.js';

        const sdk = new Audio2FaceSDK();
        let audioContext = null;
        let mediaStream = null;
        let isProcessing = false;
        let animationId = null;
        let chunkCount = 0;
        let lastFpsUpdate = performance.now();
        let fps = 0;

        const modelStatus = document.getElementById('modelStatus');
        const outputStatus = document.getElementById('outputStatus');
        const blendshapesContainer = document.getElementById('blendshapes');
        const visualizer = document.getElementById('visualizer');
        const canvasCtx = visualizer.getContext('2d');
        const progressFill = document.getElementById('progressFill');

        async function loadModelAutomatically() {
            const possiblePaths = ['network_actual.onnx', 'network.onnx', 'model.onnx'];
            
            for (let i = 0; i < possiblePaths.length; i++) {
                const path = possiblePaths[i];
                try {
                    modelStatus.textContent = `Checking for model at ${path}...`;
                    progressFill.style.width = `${((i + 0.5) / possiblePaths.length) * 50}%`;
                    
                    const response = await fetch(path, { method: 'HEAD' });
                    if (!response.ok) continue;
                    
                    const contentLength = response.headers.get('content-length');
                    const size = contentLength ? (parseInt(contentLength) / 1024 / 1024).toFixed(1) : 'unknown';
                    
                    if (size !== 'unknown' && parseFloat(size) < 1) {
                        modelStatus.textContent = `${path} is too small (${size}MB), checking next...`;
                        continue;
                    }
                    
                    modelStatus.textContent = `Loading model (${size}MB)... This may take a moment.`;
                    progressFill.style.width = '50%';
                    
                    const startTime = performance.now();
                    
                    const modelResponse = await fetch(path);
                    const modelBlob = await modelResponse.blob();
                    
                    progressFill.style.width = '75%';
                    modelStatus.textContent = 'Initializing inference session...';
                    
                    const useGPU = true;
                    await sdk.loadModel(modelBlob, { useGPU });
                    
                    const loadTime = Math.round(performance.now() - startTime);
                    const backend = sdk.isWebGPUSupported() && useGPU ? 'WebGPU' : 'WASM';
                    
                    progressFill.style.width = '100%';
                    modelStatus.innerHTML = `Model loaded successfully in ${loadTime}ms using ${backend} backend`;
                    modelStatus.className = 'status success';
                    
                    document.getElementById('modelStats').style.display = 'grid';
                    document.getElementById('backend').textContent = backend;
                    document.getElementById('inputs').textContent = sdk.session.inputNames.length;
                    document.getElementById('outputs').textContent = sdk.session.outputNames.length;
                    document.getElementById('loadTime').textContent = loadTime + 'ms';
                    
                    document.getElementById('startMic').disabled = false;
                    document.getElementById('audioFile').disabled = false;
                    document.getElementById('processFile').disabled = false;
                    outputStatus.textContent = 'Model ready! Start microphone or select audio file.';
                    outputStatus.className = 'status';
                    
                    return;
                } catch (err) {
                    console.warn(`Failed to load ${path}:`, err.message);
                    continue;
                }
            }
            
            modelStatus.innerHTML = 'Error: Could not find a valid model file. Please ensure network_actual.onnx or network.onnx exists in the same directory.';
            modelStatus.className = 'status error';
            progressFill.style.width = '100%';
            progressFill.style.background = '#ff6b6b';
        }

        window.addEventListener('load', loadModelAutomatically);

        document.getElementById('startMic').addEventListener('click', async () => {
            try {
                audioContext = new (window.AudioContext || window.webkitAudioContext)({
                    sampleRate: 16000
                });
                
                mediaStream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        sampleRate: 16000,
                        channelCount: 1,
                        echoCancellation: false,
                        noiseSuppression: false
                    } 
                });
                
                const source = audioContext.createMediaStreamSource(mediaStream);
                const bufferSize = 4096;
                
                let scriptNode;
                if (audioContext.createScriptProcessor) {
                    scriptNode = audioContext.createScriptProcessor(bufferSize, 1, 1);
                } else {
                    outputStatus.textContent = 'Your browser does not support ScriptProcessorNode';
                    outputStatus.className = 'status error';
                    return;
                }

                scriptNode.onaudioprocess = (e) => {
                    if (isProcessing) return;
                    const inputData = e.inputBuffer.getChannelData(0);
                    processAudioRealtime(inputData);
                };

                source.connect(scriptNode);
                scriptNode.connect(audioContext.destination);

                document.getElementById('startMic').disabled = true;
                document.getElementById('stopMic').disabled = false;
                document.getElementById('audioStats').style.display = 'grid';
                outputStatus.textContent = 'Realtime processing active...';
                outputStatus.className = 'status success';
            } catch (err) {
                outputStatus.textContent = 'Error accessing microphone: ' + err.message;
                outputStatus.className = 'status error';
            }
        });

        document.getElementById('stopMic').addEventListener('click', () => {
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
            }
            if (audioContext) {
                audioContext.close();
            }
            if (animationId) {
                cancelAnimationFrame(animationId);
            }
            document.getElementById('startMic').disabled = false;
            document.getElementById('stopMic').disabled = true;
            document.getElementById('audioStats').style.display = 'none';
            outputStatus.textContent = 'Microphone stopped';
            outputStatus.className = 'status';
        });

        document.getElementById('processFile').addEventListener('click', async () => {
            const fileInput = document.getElementById('audioFile');
            if (!fileInput.files.length) {
                outputStatus.textContent = 'Please select an audio file';
                outputStatus.className = 'status error';
                return;
            }

            outputStatus.textContent = 'Processing audio file...';
            outputStatus.className = 'status loading';
            
            try {
                const startTime = performance.now();
                const result = await sdk.processAudioFile(fileInput.files[0]);
                const duration = Math.round(performance.now() - startTime);
                
                displayResults(result);
                outputStatus.innerHTML = `Processing complete! ${result.frameCount} frames in ${duration}ms`;
                outputStatus.className = 'status success';
            } catch (err) {
                outputStatus.textContent = 'Error: ' + err.message;
                outputStatus.className = 'status error';
                console.error(err);
            }
        });

        async function processAudioRealtime(audioData) {
            isProcessing = true;
            const startTime = performance.now();
            
            try {
                const result = await sdk.processAudioChunk(audioData);
                displayResults(result);
                
                chunkCount++;
                const now = performance.now();
                if (now - lastFpsUpdate > 1000) {
                    fps = chunkCount;
                    chunkCount = 0;
                    lastFpsUpdate = now;
                    document.getElementById('fps').textContent = fps;
                }
                document.getElementById('latency').textContent = Math.round(performance.now() - startTime);
                document.getElementById('chunks').textContent = chunkCount + (fps > 0 ? fps : 0);
            } catch (err) {
                console.error('Processing error:', err);
            } finally {
                isProcessing = false;
            }
        }

        function displayResults(result) {
            blendshapesContainer.innerHTML = '';
            
            if (result.blendshapes && result.blendshapes.length > 0) {
                result.blendshapes.forEach((bs) => {
                    const div = document.createElement('div');
                    div.className = 'blendshape';
                    div.innerHTML = `
                        <div class="blendshape-header">
                            <span class="blendshape-name">${bs.name}</span>
                            <span class="blendshape-value">${bs.value.toFixed(3)}</span>
                        </div>
                        <div class="bar">
                            <div class="bar-fill" style="width: ${Math.min(100, bs.value * 100)}%"></div>
                        </div>
                    `;
                    blendshapesContainer.appendChild(div);
                });
            }

            if (result.jaw > 0) {
                const div = document.createElement('div');
                div.className = 'blendshape';
                div.innerHTML = `
                    <div class="blendshape-header">
                        <span class="blendshape-name">Jaw Open</span>
                        <span class="blendshape-value">${result.jaw.toFixed(3)}</span>
                    </div>
                    <div class="bar">
                        <div class="bar-fill" style="width: ${Math.min(100, result.jaw * 100)}%"></div>
                    </div>
                `;
                blendshapesContainer.appendChild(div);
            }
        }

        function drawVisualizer() {
            animationId = requestAnimationFrame(drawVisualizer);
            const width = visualizer.width = visualizer.offsetWidth;
            const height = visualizer.height = visualizer.offsetHeight;
            
            canvasCtx.fillStyle = '#0f3460';
            canvasCtx.fillRect(0, 0, width, height);
            
            if (isProcessing) {
                canvasCtx.fillStyle = '#00d4ff';
                canvasCtx.fillRect(0, height - 5, width, 5);
            }
        }
        drawVisualizer();
    </script>
</body>
</html>